# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

!pip uninstall -y scikit-learn
!pip install scikit-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import seaborn as sns
import sklearn.datasets
from xgboost import XGBRegressor
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score

"""Import Boston housing data"""

data_url = "http://lib.stat.cmu.edu/datasets/boston"
raw_df = pd.read_csv(data_url, sep="\s+", skiprows=22, header=None)
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
target = raw_df.values[1::2, 2]

print(target)

# Loading the dataset to a Pandas Dataframe
house_price_dataframe = pd.DataFrame(data)

raw_df.head()

# add the target column to dataframe
house_price_dataframe['price'] = target

# checking the number of rows and columns in the data
house_price_dataframe.shape

#check for missing values
house_price_dataframe.isnull().sum()

# statistical measure of the dataset
house_price_dataframe.describe()

"""Understanding the correlation between various feature in the dataset
1.postive
2.negative
"""

correlation = house_price_dataframe.corr()

# construction a heatmap
plt.figure(figsize=(10,10))
sns.heatmap(correlation,cbar=True, square=True , fmt='.1f', annot=True,annot_kws={'size':8},cmap='Blues')

"""Splitting the data and target"""

X = house_price_dataframe.drop(['price'], axis=1)
Y = house_price_dataframe['price']

print(X)
print(Y)

"""Splitting the data into train data and test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size= 0.2, random_state= 2)

print(X.shape, X_train.shape, X_test.shape)

"""Model training
XCBoost Regressor
"""

model=XGBRegressor()

from xgboost import XGBRegressor

# Define the model
model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)

# Instead of just writing `model`, use `print(model)`
print(model)

from xgboost import XGBRegressor
from sklearn.utils.estimator_checks import check_estimator

model = XGBRegressor()

# Check if Scikit-learn recognizes XGBoost properly
try:
    print(model.get_params())  # Should print model parameters
    print("XGBRegressor initialized successfully!")
except AttributeError as e:
    print("Error initializing XGBRegressor:", e)

# Check if the issue is from Scikit-learn's compatibility
try:
    check_estimator(model)
except Exception as e:
    print("check_estimator error:", e)
x=model.fit(X_train, Y_train)

"""Evalution

Prediction training data
"""

# accuracy for prediction on training data
training_data_prediction = model.predict(X_train)

print(training_data_prediction)

# R squred error
score_1 = metrics.r2_score(Y_train, training_data_prediction)


# Mean Absolute Error

score_2 = metrics.mean_absolute_error(Y_train, training_data_prediction)

print("R squared error : ", score_1)
print("Mean Absolute Error : ", score_2)

#Visulaize the actual prices and predicted prices



"""Prediction on the dataset"""

# accuracy for testing data
test_data_prediction = model.predict(X_test)

# R squred error
score_1 = metrics.r2_score(Y_test, test_data_prediction)


# Mean Absolute Error

score_2 = metrics.mean_absolute_error(Y_test, test_data_prediction)

print("R squared error : ", score_1)
print("Mean Absolute Error : ", score_2)

import numpy as np
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

# Load dataset
data = load_iris()
X = data.data
y = data.target

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train the XGBoost Classifier
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)

# Define function for user input
def get_user_input():
    print("Enter feature values one by one:")
    feature_values = []

    for i in range(X.shape[1]):  # Ensure the correct number of features
        value = float(input(f"Enter value for feature {i+1}: "))
        feature_values.append(value)

    # Convert input to numpy array and scale
    user_input = np.array(feature_values).reshape(1, -1)
    user_input_scaled = scaler.transform(user_input)  # Apply the same scaling

    return user_input_scaled

# Get user input
user_input = get_user_input()

# Make prediction
predicted_class = xgb_model.predict(user_input)
print(f"Predicted Class: {predicted_class[0]}")
1

import numpy as np
import pandas as pd
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error


df = pd.read_csv("/content/house.csv")


print(df.head())

# Define features (X) and target (y)
X = df.drop(columns=['price'])  # Drop 'price' since it's the target variable
y = df['price']

# Split dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train an XGBoost Regressor
model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
model.fit(X_train_scaled, y_train)

# Evaluate the model
y_pred = model.predict(X_test_scaled)
print(f"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.2f}")

# Function to get user input and predict house price
def predict_house_price():
    print("\nEnter house details:")
    feature_values = []

    for feature in X.columns:
        value = float(input(f"Enter value for {feature}: "))
        feature_values.append(value)

    # Prepare input for prediction
    user_input = np.array([feature_values]).reshape(1, -1)
    user_input_scaled = scaler.transform(user_input)

    # Predict price
    predicted_price = model.predict(user_input_scaled)
    print(f"\nEstimated House Price: ${predicted_price[0]:,.2f}")

# Get user input and predict house price
predict_house_price()